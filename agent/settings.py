
Analyzer_settings = {
    0:{
        "server_name": "deepseek",
        "model": "deepseek-reasoner",
        "max_tokens": 16384,
        "temperature": 1.0,
        "top_p": 1.0
    },
    1:{
        "server_name": "qwen",
        "model": "qwen3.5-plus-2026-02-15",
        "max_tokens": 16384,
        "temperature": 1.0,
        "top_p": 1.0
    },
    2:{
        "server_name": "kimi",
        "model": "kimi-k2.5",
        "max_tokens": 16384,
        "temperature": 1.0,
        "top_p": 1.0
    }
}

Coder_settings = {
    0:{
        "server_name": "deepseek",
        "model": "deepseek-reasoner",
        "max_tokens": 16384,
        "temperature": 0.0,
        "top_p": 1.0
    },
    1:{
        "server_name": "qwen",
        "model": "qwen3.5-plus-2026-02-15",
        "max_tokens": 16384,
        "temperature": 0.0,
        "top_p": 1.0
    },
    2:{
        "server_name": "kimi",
        "model": "kimi-k2.5",
        "max_tokens": 16384,
        "temperature": 0.0,
        "top_p": 1.0
    }
}


Planner_settings = {
    0:{
        "server_name": "deepseek",
        "model": "deepseek-reasoner",
        "max_tokens": 4096,
        "temperature": 1.0,
        "top_p": 1.0
    },
    1:{
        "server_name": "qwen",
        "model": "qwen3.5-plus-2026-02-15",
        "max_tokens": 4096,
        "temperature": 1.0,
        "top_p": 1.0
    },
    2:{
        "server_name": "kimi",
        "model": "kimi-k2.5",
        "max_tokens": 4096,
        "temperature": 1.0,
        "top_p": 1.0
    }
}

Validator_settings = {
    0:{
        "server_name": "deepseek",
        "model": "deepseek-reasoner",
        "max_tokens": 16384,
        "temperature": 1.0,
        "top_p": 1.0
    },
    1:{
        "server_name": "qwen",
        "model": "qwen3.5-plus-2026-02-15",
        "max_tokens": 16384,
        "temperature": 1.0,
        "top_p": 1.0
    },
    2:{
        "server_name": "kimi",
        "model": "kimi-k2.5",
        "max_tokens": 16384,
        "temperature": 1.0,
        "top_p": 1.0
    }
}

